---
title: K8s
description: 
date: 2025-11-08
categories:
    - 
    - 
---

# Kubernetes (K8s) 基础及部署文档

## 1. Kubernetes 部署方式总览

Kubernetes（K8s）作为当前主流的容器编排平台，提供了多种部署方式以适应不同的应用场景，从个人开发学习到大规模企业生产，每种方式都有其独特的优势和局限性。选择合适的部署方式对于项目的成功至关重要，它直接影响到部署效率、集群的稳定性、可维护性以及资源成本。主要的部署方式可以分为三类：用于本地快速体验的单节点部署工具 `minikube`、官方推荐的自动化部署工具 `kubeadm`，以及适用于高度定制化生产环境的二进制包手动部署。理解这三种部署方式的特点和适用场景，是进行 Kubernetes 集群规划和实施的第一步，能够帮助技术团队根据自身的资源、技术能力和业务需求做出最优选择。

### 1.1. minikube

`minikube` 是 Kubernetes 官方提供的工具，其核心目标是为开发者和学习者提供一个在本地计算机上快速搭建单节点 Kubernetes 集群的解决方案。它通过在虚拟机（如 VirtualBox、Hyper-V）或容器（如 Docker）中创建一个包含所有必要组件的轻量级集群，极大地降低了 Kubernetes 的入门门槛。因此，`minikube` 的主要适用场景是个人开发环境、功能测试、CI/CD 流程中的自动化测试以及技术教学。开发者可以在自己的笔记本电脑上模拟一个完整的 K8s 环境，进行应用程序的容器化、部署、调试和测试，而无需担心对生产环境造成影响。然而，由于其单节点的架构限制，`minikube` 无法模拟多节点集群的复杂性，例如网络策略、跨节点 Pod 通信和负载均衡等高级功能，因此它明确不适合用于承载任何生产级别的业务负载。

#### 1.1.1. 适用场景

`minikube` 的主要适用场景是**本地开发、学习和功能测试**。对于初次接触 Kubernetes 的开发者和运维人员来说，`minikube` 提供了一个零门槛的入门途径。开发者可以在自己的笔记本电脑上快速启动一个 Kubernetes 环境，用于开发和调试云原生应用，验证 Dockerfile 和 Kubernetes YAML 配置文件的正确性。此外，它也是技术分享、教学和演示的理想工具，讲师或分享者可以迅速搭建一个标准化的环境来展示 Kubernetes 的各项功能，而无需依赖复杂的云基础设施。例如，开发者可以使用 `minikube` 来测试一个微服务应用的部署、服务发现、配置管理和扩缩容等操作，从而加深对 Kubernetes 工作原理的理解。由于其资源占用相对较低，它也适合在资源有限的环境中进行 Kubernetes 相关的实验和探索 。

#### 1.1.2. 特点说明

`minikube` 的最大特点是其**部署的便捷性和快速性**。用户只需执行一条简单的命令，如 `minikube start`，即可在几分钟内启动一个功能齐全的 Kubernetes 集群。它会自动处理所有底层依赖，包括容器运行时（如 Docker）、kubelet、kubeadm 和 kubectl 等组件的安装与配置。`minikube` 支持多种 Kubernetes 版本，允许用户轻松切换以测试不同版本的功能和兼容性。此外，它还提供了一系列插件（addons），如 Dashboard、Ingress、Metrics-Server 等，可以通过简单的命令启用，进一步丰富了本地开发环境的功能。然而，`minikube` 的局限性也同样明显：它是一个**单节点伪集群**，Master 和 Node 角色都运行在同一个虚拟机上，无法提供高可用性。其资源受限于宿主机，性能和扩展性都非常有限，仅能满足轻量级的开发和测试需求。

### 1.2. kubeadm

`kubeadm` 是由 Google 推出并已成为 Kubernetes 官方推荐的集群部署工具，旨在简化生产级 Kubernetes 集群的初始化和管理过程。它适用于从测试环境到大规模生产环境的各种场景。对于希望深入学习 Kubernetes 架构和最佳实践的技术人员来说，`kubeadm` 是一个理想的工具，因为它在自动化部署的同时，也暴露了集群配置的许多细节，帮助用户理解集群内部的工作原理。对于企业而言，`kubeadm` 提供了一种标准化、可重复的部署流程，能够快速搭建出符合生产要求的、高可用的 Kubernetes 集群。它支持多 Master 节点部署，通过集成外部负载均衡器实现控制平面的高可用，满足了企业级应用对稳定性的严苛要求。

#### 1.2.1. 适用场景

`kubeadm` 的适用场景非常广泛，主要面向**测试和生产环境的部署**。对于希望在物理机、虚拟机或云服务器上搭建一个功能完整、可扩展的 Kubernetes 集群的用户来说，`kubeadm` 是官方推荐的首选工具。它特别适合那些需要**高可用（HA）** 的集群部署，用户可以通过 `kubeadm` 轻松地初始化一个包含多个 Master 节点的控制平面，从而实现集群管理组件的冗余和故障转移。此外，`kubeadm` 也广泛应用于**学习和研究**。通过使用 `kubeadm`，用户可以深入了解 Kubernetes 集群的内部架构和组件之间的交互方式，学习官方推荐的集群配置和最佳实践。对于企业用户而言，`kubeadm` 提供了一个稳定、可靠且易于维护的部署方案，能够满足生产环境对安全性、稳定性和可扩展性的要求。

#### 1.2.2. 特点说明

`kubeadm` 的核心优势在于其 **“一键初始化”和“一键加入”** 的能力。在 Master 节点上，通过 `kubeadm init` 命令，工具会自动完成一系列复杂的初始化任务，包括生成集群所需的 CA 证书、配置 etcd 集群、启动 API Server、Controller Manager 和 Scheduler 等控制平面组件。在 Worker 节点上，只需执行 `kubeadm join` 命令，并提供在初始化时生成的 token 和证书哈希值，即可将节点安全地加入到集群中。`kubeadm` 确保了集群中所有核心组件的版本一致性，避免了手动部署时可能出现的版本不匹配问题。此外，它还提供了 `kubeadm upgrade` 命令，用于平滑地升级集群版本，极大地简化了集群的维护工作。虽然 `kubeadm` 自动化程度很高，但它并不负责底层基础设施的搭建和容器运行时（如 Docker）的安装，这些准备工作仍需用户手动完成。

### 1.3. 二进制包

二进制包部署是 Kubernetes 最原始、最基础的部署方式，它要求用户从官方 GitHub 仓库下载各个核心组件（如 kube-apiserver, kube-controller-manager, kube-scheduler, kubelet, kube-proxy, etcd）的预编译二进制文件，然后手动在每台服务器上进行部署和配置。这种方式主要适用于对集群有高度定制化需求的企业生产环境。例如，在某些对安全性、性能或网络有特殊要求的场景下，默认的部署工具可能无法满足需求，此时就需要通过二进制包部署来精细调整每个组件的配置参数、启动脚本和证书体系。此外，对于希望完全掌控集群每一个细节、深入理解 Kubernetes 内部机制的资深运维和架构师来说，二进制部署也是一个宝贵的学习和实践过程。

#### 1.3.1. 适用场景

二进制包部署方式主要适用于**对集群有高度定制化需求的企业生产环境**。例如，一些大型企业或云服务提供商，可能需要对 Kubernetes 的核心组件进行深度定制，以实现特定的功能、性能优化或安全加固。在这种情况下，使用二进制包部署可以让他们完全控制每个组件的版本、配置和运行方式。此外，对于一些**离线或网络受限的环境**，二进制包部署也是一种可行的选择。用户可以在一个有网络的环境中下载好所有需要的二进制文件和镜像，然后将它们拷贝到目标环境中进行部署，从而避免了在线拉取镜像的问题。这种方式也适用于那些希望**从零开始学习和理解 Kubernetes 内部工作原理**的高级用户，通过手动部署每个组件，可以更深入地理解 K8s 的架构和各个组件之间的协作关系。

#### 1.3.2. 特点说明

二进制包部署的最大特点是其**无与伦比的灵活性和可控性**。用户可以完全自主地决定每个组件的安装位置、配置参数、证书策略以及服务启动方式，从而实现对集群的深度定制。这种方式不依赖于任何自动化工具，因此可以避免因工具本身的限制或 bug 带来的问题。然而，这种灵活性的代价是**极高的部署复杂度和维护成本**。手动部署过程繁琐且容易出错，需要编写大量的配置文件和 systemd 服务单元文件。集群的搭建、扩容、缩容和版本升级都需要耗费大量的人力和时间，并且对运维人员的技术水平要求非常高。证书的管理和轮换、高可用配置等关键任务都需要手动实现，任何一个环节的疏忽都可能导致集群故障。因此，除非有特殊需求，否则一般不推荐在生产环境中采用这种部署方式。

## 2. K8s 集群角色与组件说明

一个 Kubernetes 集群由多个协同工作的组件构成，这些组件根据其功能可以被划分为不同的角色。理解这些角色及其核心组件的作用，是掌握 Kubernetes 架构和进行有效运维的基础。集群主要由两类节点组成：Master 节点（控制平面）和 Node 节点（工作节点），它们共同管理着集群的状态和运行在其上的容器化应用。此外，ETCD 作为集群的“大脑”，负责存储所有关键数据，是整个系统正常运行的基石。

### 2.1. Master 节点

Master 节点，也被称为控制平面（Control Plane），是 Kubernetes 集群的“指挥中心”。它的主要职责是管理和控制整个集群的状态，包括应用的调度、生命周期管理、服务发现、负载均衡以及集群的扩缩容等。Master 节点本身不运行任何用户的业务容器，而是专注于集群的“大脑”功能。其核心组件包括 `kube-apiserver`、`kube-controller-manager`、`kube-scheduler` 和 `etcd`。这些组件共同协作，维持着集群的期望状态，并响应用户的各种操作请求。

#### 2.1.1. 作用说明

Master 节点的主要作用是**管理和控制整个 Kubernetes 集群**。它不直接运行业务容器，而是专注于集群的“大脑”功能。具体来说，Master 节点的作用包括：
1.  **API 服务**：通过 `kube-apiserver` 组件，为集群内外的所有组件提供一个统一的、RESTful 风格的 API 接口。所有的操作，无论是用户通过 `kubectl` 发起的命令，还是集群内部组件之间的通信，都必须通过 `kube-apiserver` 进行。
2.  **状态管理**：通过与 `etcd` 的交互，存储和管理集群的所有状态信息，包括节点信息、Pod 信息、Service 信息、配置信息等。`etcd` 保证了集群状态数据的一致性和高可用性。
3.  **调度决策**：`kube-scheduler` 负责将新创建的 Pod 分配到最合适的 Node 节点上运行。它会根据一系列的调度算法和策略，综合考虑节点的资源使用情况、亲和性/反亲和性规则、污点和容忍度等因素，做出最优的调度决策。
4.  **控制循环**：`kube-controller-manager` 中包含了一系列的控制器（Controller），如 Node Controller、Replication Controller、Endpoint Controller 等。这些控制器通过不断监测集群的实际状态，并与期望状态进行比较，来确保集群始终维持在用户期望的状态。例如，如果某个 Pod 意外崩溃，Replication Controller 会自动创建一个新的 Pod 来替代它。
5.  **集群管理**：Master 节点还负责处理节点的加入和移除、集群的升级和维护等管理任务。

### 2.2. Node 节点

Node 节点，也被称为工作节点（Worker Node），是 Kubernetes 集群中实际运行业务容器的节点。每个 Node 节点上都运行着一系列代理组件，主要包括 `kubelet`、`kube-proxy` 和容器运行时（如 Docker 或 containerd）。这些组件负责与 Master 节点通信，并根据 Master 节点的指令来管理容器的生命周期和网络。Node 节点是集群的计算资源提供者，它们的数量和性能直接决定了集群能够承载的工作负载规模。当 `kube-scheduler` 将一个 Pod 分配到某个 Node 节点上时，该节点的 `kubelet` 会接收到这个指令，并与容器运行时协作，拉取镜像、创建容器、配置网络和挂载卷，最终启动 Pod。同时，`kube-proxy` 会负责为该 Pod 配置网络规则，使其能够被集群内外的其他服务访问。

#### 2.2.1. 作用说明

Node 节点的主要作用是**作为集群的工作负载承载者，负责运行和管理用户部署的应用容器**。具体来说，Node 节点的作用包括：
1.  **容器管理**：`kubelet` 是 Node 节点上的核心代理组件，它负责与 Master 节点的 `kube-apiserver` 通信，接收 Pod 的创建、更新和删除指令。然后，`kubelet` 会与容器运行时（如 Docker）交互，执行具体的容器操作，确保 Pod 中的容器按照预期状态运行。
2.  **资源管理**：`kubelet` 会持续监控本节点的 CPU、内存、磁盘等资源的使用情况，并将这些信息上报给 Master 节点。这些信息是 `kube-scheduler` 进行调度决策的重要依据。
3.  **网络代理**：`kube-proxy` 负责实现 Kubernetes Service 的网络代理和负载均衡功能。它会在每个 Node 节点上维护一套网络规则（基于 iptables 或 IPVS），将发送到 Service 虚拟 IP 的流量转发到后端对应的 Pod 上。
4.  **卷管理**：`kubelet` 还负责为 Pod 挂载和卸载存储卷。它会根据 Pod 的定义，调用相应的卷插件（Volume Plugin）来挂载远程存储（如 NFS、Ceph）或本地存储到容器中。
5.  **健康检查**：`kubelet` 会对本节点上运行的容器进行健康检查（Liveness Probe 和 Readiness Probe），并根据检查结果决定是否重启容器或将其从 Service 的负载均衡池中移除。

### 2.3. ETCD

ETCD 是一个高可用的分布式键值存储系统，在 Kubernetes 集群中扮演着至关重要的角色。它被用作集群的后端存储，用于保存所有的集群状态数据和配置信息。Kubernetes 的所有组件，包括 Master 节点和 Node 节点，都通过 `kube-apiserver` 与 ETCD 进行交互，以读取或写入数据。ETCD 保证了集群状态数据的一致性、可靠性和高可用性。当集群中的任何资源对象（如 Pod、Service、ConfigMap 等）发生变化时，这些变化都会被记录到 ETCD 中。控制平面组件（如控制器）会监听 ETCD 中的数据变化，并根据这些变化来执行相应的操作，从而驱动集群达到期望的状态。可以说，ETCD 是 Kubernetes 集群的“唯一事实来源”（Single Source of Truth），是整个集群能够正常运行的基石。

#### 2.3.1. 作用说明

ETCD 在 Kubernetes 集群中的作用可以概括为以下几点：
1.  **状态存储**：ETCD 存储了 Kubernetes 集群的所有状态信息，包括节点信息、Pod 信息、Service 信息、网络策略、RBAC 策略等。所有对集群状态的查询和修改操作，最终都会转化为对 ETCD 的读写操作。
2.  **配置管理**：Kubernetes 的各种配置信息，如 ConfigMap 和 Secret，也存储在 ETCD 中。这使得应用的配置可以与代码分离，方便进行统一管理和动态更新。
3.  **服务发现**：ETCD 可以用于实现服务发现机制。服务实例可以将自己的地址和端口信息注册到 ETCD 中，而其他服务则可以通过查询 ETCD 来发现这些实例。
4.  **分布式锁**：ETCD 提供了分布式锁的功能，可以用于在分布式系统中实现资源的互斥访问，保证操作的原子性。Kubernetes 中的一些控制器会使用 ETCD 的锁来避免并发冲突。
5.  **高可用性**：ETCD 本身是一个高可用的分布式系统，通常以奇数个节点（如 3、5、7）的集群模式运行。通过 Raft 一致性算法，ETCD 能够在部分节点失效的情况下，继续提供服务，保证了集群状态数据的可靠性和可用性。在生产环境中，通常会部署一个独立的 ETCD 集群，以确保其性能和稳定性。

## 3. 基于 kubeadm 部署 K8s 集群（详细流程）

使用 `kubeadm` 部署 Kubernetes 集群是一个系统性的工程，涉及从基础环境准备到最终集群验证的多个步骤。本流程将详细阐述在一个典型的三节点（1 Master + 2 Nodes）环境中，如何通过 `kubeadm` 工具搭建一个稳定、可用的 Kubernetes 集群。整个过程需要在所有节点上执行一些通用的配置，然后在 Master 节点上进行初始化，最后将 Node 节点加入集群。为了确保部署的顺利进行，每一步都需要严格按照操作指南执行，并对可能出现的问题进行排查。

### 3.1. 主机准备与环境初始化

在正式安装 Kubernetes 组件之前，必须对所有节点进行基础的环境配置，以确保节点之间能够正常通信，并为后续的安装步骤扫清障碍。这包括设置唯一的主机名、配置主机名与 IP 的映射关系，以及设置 SSH 免密登录，这些准备工作是构建一个可管理、可扩展集群的基础。

#### 3.1.1. 修改主机名

为集群中的每个节点设置一个唯一且具有描述性的主机名是至关重要的。这不仅便于管理员识别和管理节点，也是 Kubernetes 集群内部组件进行通信和节点注册的基础。在 CentOS 7 系统中，可以使用 `hostnamectl` 命令来永久性地修改主机名。例如，在三节点集群中，可以分别将三个节点命名为 `k8s-master`、`k8s-node1` 和 `k8s-node2`。执行命令 `hostnamectl set-hostname k8s-master` 后，需要重新打开一个终端会话或执行 `bash` 命令，以使新的主机名在当前会话中生效。一个清晰的主机名命名规范，如 `k8s-{role}-{number}`，可以极大地提升集群的可读性和可维护性，尤其是在节点数量较多的大规模集群中。

#### 3.1.2. 配置 hosts 文件

为了确保集群内部节点之间可以通过主机名直接进行通信，而不依赖于外部的 DNS 服务，需要在每个节点的 `/etc/hosts` 文件中配置静态的主机名到 IP 地址的映射。这是一个关键步骤，因为 Kubernetes 的许多内部组件（如 kubelet 向 API Server 注册）都依赖于主机名解析。在每个节点的 `/etc/hosts` 文件中，应添加所有集群节点的 IP 和主机名对应关系。例如，可以追加如下内容：
```
192.168.200.101 k8s-master
192.168.200.102 k8s-node1
192.168.200.103 k8s-node2
```
配置完成后，可以使用 `ping` 命令测试各节点之间通过主机名的连通性，例如 `ping k8s-node1`，以确保网络配置正确无误。这个简单的配置可以避免因 DNS 解析问题导致的集群初始化失败或节点无法加入等常见错误。

#### 3.1.3. SSH 免密配置

在集群的部署和日常运维过程中，经常需要在 Master 节点上远程执行命令到各个 Node 节点，例如分发文件、执行脚本等。为了避免每次都输入密码，配置 SSH 免密登录是提高效率的必要步骤。该配置主要在 Master 节点上进行。首先，在 Master 节点上执行 `ssh-keygen -t rsa` 命令生成 SSH 密钥对（如果尚未生成）。然后，使用 `ssh-copy-id` 命令将生成的公钥（`~/.ssh/id_rsa.pub`）复制到各个 Node 节点的 `~/.ssh/authorized_keys` 文件中。例如，执行 `ssh-copy-id k8s-node1` 和 `ssh-copy-id k8s-node2`。完成配置后，从 Master 节点 SSH 登录到 Node 节点将不再需要输入密码。此外，为了确保所有节点的 `/etc/hosts` 文件保持一致，可以使用 `scp` 命令将 Master 节点上配置好的文件分发到所有 Node 节点，例如 `scp /etc/hosts k8s-node1:/etc/`。

### 3.2. 系统环境优化

为了确保 Kubernetes 集群能够稳定运行，需要对操作系统的默认配置进行一系列优化。这些优化措施旨在消除可能干扰 K8s 组件正常工作的系统设置，例如安全策略、防火墙规则、交换分区以及时间同步等。这些步骤需要在集群的所有节点上执行，以保证环境的一致性和集群的整体健康。

#### 3.2.1. 关闭 SELinux

SELinux (Security-Enhanced Linux) 是一个 Linux 内核的安全模块，它提供了强制访问控制（MAC）机制，可以限制进程对文件、网络端口等资源的访问。虽然 SELinux 能够显著提升系统的安全性，但其严格的访问控制策略可能会与 Kubernetes 组件（如 kubelet、容器运行时）的正常操作产生冲突，导致 Pod 无法启动、网络通信失败等问题。为了避免这些潜在的权限问题，在部署 Kubernetes 集群时，通常建议将 SELinux 设置为禁用（disabled）或宽容（permissive）模式。可以通过执行 `setenforce 0` 命令临时关闭 SELinux，并通过修改 `/etc/selinux/config` 文件中的 `SELINUX=disabled` 来永久禁用，以确保系统重启后设置依然生效。

#### 3.2.2. 关闭防火墙

Kubernetes 集群需要开放一系列特定的网络端口以支持其内部组件之间的通信以及外部访问。例如，API Server 默认监听 6443 端口，kubelet 监听 10250 端口，而各种网络插件（如 Calico、Flannel）也需要使用特定的端口进行数据传输。系统自带的防火墙（如 firewalld）可能会阻止这些必要的网络流量，导致集群初始化失败或节点间无法正常通信。为了简化网络配置并避免端口冲突，通常在部署集群时会选择关闭防火墙。可以通过 `systemctl stop firewalld` 命令立即停止防火墙服务，并使用 `systemctl disable firewalld` 命令禁止其在系统启动时自动运行。在生产环境中，更安全的做法是配置精细的防火墙规则，只允许必要的端口通信，但在学习和测试环境中，直接关闭防火墙是更常见的做法。

#### 3.2.3. 禁用 Swap

Kubernetes 的设计哲学之一是保证应用的性能和可预测性。Swap 分区（交换空间）是当物理内存不足时，操作系统用来临时存储内存数据的一块磁盘空间。虽然 Swap 可以在内存紧张时防止系统崩溃，但其基于磁盘的读写速度远低于物理内存，会严重影响容器的运行性能。Kubernetes 的调度器（kube-scheduler）在调度 Pod 时，会假设所有节点的可用内存都是真实的物理内存。如果允许使用 Swap，可能会导致调度器做出错误的决策，将 Pod 调度到实际内存资源已经不足的节点上，从而引发性能问题。因此，Kubernetes 官方明确要求在所有节点上禁用 Swap。可以通过执行 `swapoff -a` 命令临时关闭 Swap，并通过编辑 `/etc/fstab` 文件，注释掉或删除与 Swap 相关的挂载条目，以实现永久禁用。

#### 3.2.4. 时间同步

在分布式系统中，保持所有节点之间的时间同步至关重要。Kubernetes 集群中的许多组件，如证书验证、日志聚合、事件排序等，都依赖于精确的时间。如果集群中各节点的时间偏差过大，可能会导致 TLS 证书认证失败、日志时间戳混乱、调度决策异常等一系列问题。为了确保时间的一致性，需要为所有节点配置时间同步服务。可以使用 `ntpdate` 工具手动同步时间，例如 `ntpdate time2.aliyun.com`。为了实现自动同步，可以将该命令添加到 `crontab` 定时任务中，例如 `*/5 * * * * /usr/sbin/ntpdate time2.aliyun.com > /dev/null 2>&1`，表示每 5 分钟同步一次时间。此外，还应使用 `timedatectl set-timezone Asia/Shanghai` 命令将所有节点的时区统一设置为东八区


